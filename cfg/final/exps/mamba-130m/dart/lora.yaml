batch_size: 4
data: dart
eval_gen:
  max_length: 1024
  min_length: 5
  num_beams: 5
learning_rate: 0.004
model: state-spaces/mamba-130m
no_save: false
num_epochs: 10
peft: cfg/final/peft/mamba-130m/dart/lora.json
prec: bf16
